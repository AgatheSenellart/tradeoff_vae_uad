config:
  _target_: mvae_ad.trainers.CapsTrainerConfig
  num_epochs: 100
  per_device_train_batch_size: ??
  per_device_eval_batch_size: ??
  learning_rate: 1e-4
  seed: ${seed}
  steps_predict: 5
  scheduler_cls: ReduceLROnPlateau
  scheduler_params:
    factor: 0.5
    patience: 15
  optimizer_cls: Adam
  optimizer_params:
    weight_decay: 0.4
  gradient_clipping_max_norm: null
  start_keep_best_epoch: 10
  save_nifti_reconstruction: false
  beta_schedule_fct: null
  beta_schedule_params:
    n_cycle: 4
    ratio: 0.5
    min_beta: 0.1
    n_augment: 30 # for single_frange_scheduler
