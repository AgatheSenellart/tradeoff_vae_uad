config:
  _target_: mvae_ad.trainers.CapsTrainerConfig
  num_epochs: 99
  per_device_train_batch_size: ??
  per_device_eval_batch_size: ??
  learning_rate: 1e-4
  seed: ${seed}
  steps_predict: 5
  scheduler_cls: CosineAnnealingLR
  scheduler_params: 
    T_max: 33
  optimizer_cls: Adam
  optimizer_params:
    weight_decay: 0.
  gradient_clipping_max_norm: null
  # window_size_for_checkpoints: 1
  start_keep_best_epoch: 33
  save_nifty_reconstruction: false
  beta_schedule_fct: frange_cycle_linear
  beta_schedule_params: 
    n_cycle: 3
    ratio: 0.5
    min_beta: 0.0
    n_augment: 30 # for single_frange_scheduler
